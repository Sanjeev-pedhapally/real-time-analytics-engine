# Event Flow Documentation

## Sequence Diagram

```mermaid
sequenceDiagram
    participant Producer
    participant Kafka
    participant Flink
    participant Cassandra
    participant Redis
    participant API
    participant Dashboard
    Producer->>Kafka: Send e-commerce events
    Kafka->>Flink: Stream events
    Flink->>Cassandra: Write windowed aggregates (historical)
    Flink->>Redis: Write real-time aggregates (pub/sub)
    API->>Cassandra: Query historical data
    API->>Redis: Query real-time data
    Dashboard->>API: REST/WebSocket for metrics
    Dashboard->>API: Subscribe for live updates
```

## Data Flow
- Events generated by Kafka Producer
- Flink jobs consume Kafka topics, process with windowing, output to Cassandra and Redis
- API service reads from Cassandra (historical) and Redis (real-time)
- Dashboard fetches metrics via API and receives live updates via WebSocket
- Monitoring stack (Prometheus/Grafana) tracks metrics across all services

## Error Handling & Circuit Breakers
- All services use consistent event schemas
- API falls back to Cassandra if Redis unavailable
- Circuit breaker patterns in Redis/Service layers
